{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any\n",
    "import json\n",
    "import arxiv\n",
    "import shutil\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pypdf import PdfReader\n",
    "from pathlib import Path\n",
    "from crossref.restful import Works\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(\"pypdf\")\n",
    "logger.setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.home() / \"metacognition\" / \"resources\"\n",
    "papers = root / \"papers\"\n",
    "books = root / \"books\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = arxiv.Client()\n",
    "\n",
    "def get_metadata(filename: str):\n",
    "    try:\n",
    "        # f\"https://export.arxiv.org/api/query?id_list={filename.split('_')[-1].removesuffix('.pdf')}&max_results=1\"\n",
    "        return next(client.results(arxiv.Search(id_list = [filename.split('_')[-1].removesuffix('.pdf')])))\n",
    "    except Exception:\n",
    "        return None \n",
    "\n",
    "df = (\n",
    "    pd.DataFrame({\"path\": papers.rglob(\"*.pdf\")})\n",
    "    .assign(filename = lambda df: df[\"path\"].apply(lambda x: x.name))\n",
    "    .assign(doi = lambda df: df[\"path\"].apply(lambda x: x.stem.replace('_', '/').lower()))\n",
    "    .loc[lambda df: df[\"doi\"].str.startswith(\"10.4855\")] # keep only arxiv papers\n",
    "    .assign(metadata = lambda df: df[\"filename\"].apply(get_metadata))\n",
    "    .dropna()\n",
    "    .assign(title = lambda df: df[\"metadata\"].apply(lambda x: x.title))\n",
    "    .assign(authors = lambda df: df[\"metadata\"].apply(lambda x: ', '.join(str(a) for a in x.authors)))\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.read_table(papers/\"index.md\", sep = \"|\", skiprows=3, usecols = [1,2,3], header = None)\n",
    "index_df.columns = [\"filename\", \"title\", \"authors\"]\n",
    "index_df[\"filename\"] = index_df[\"filename\"].apply(lambda x: (x + \".pdf\").replace(' ', ''))\n",
    "index_df = pd.concat([index_df, df[[\"filename\", \"title\", \"authors\"]]], axis=0)\n",
    "index_df[\"tags\"] = None \n",
    "index_df.to_markdown(root / \"papers_index.md\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"name\", \"metadata\"]].to_csv(\"doi.csv\", index = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = Works()\n",
    "\n",
    "def crossref_search(doi: str) -> Optional[dict[str, Any]]:\n",
    "    try:\n",
    "        return works.doi(doi)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def get_title(crossref_doi: dict) -> Optional[str]:\n",
    "    try:\n",
    "        return crossref_doi[\"title\"][0]\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "def get_authors(crossref_doi: dict) -> str:\n",
    "    try:\n",
    "        first_author = list()\n",
    "        authors = list()\n",
    "        for author in crossref_doi[\"author\"]:\n",
    "            name = f\"{author[\"given\"]} {author[\"family\"]}\"\n",
    "            if author[\"sequence\"] == \"first\":\n",
    "                first_author.append(name)\n",
    "            else:\n",
    "                authors.append(name)\n",
    "        return ', '.join(first_author + authors)\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "df = (\n",
    "    pd.DataFrame({\"path\": papers.rglob(\"*.pdf\")})\n",
    "    .assign(doi = lambda df: df[\"path\"].apply(lambda x: x.stem.replace('_', '/').lower()))\n",
    "    .loc[lambda df: df[\"doi\"].apply(lambda x: not x.startswith(\"10.4855\"))] # remove arxiv papers\n",
    "    .assign(crossref = lambda df: df[\"doi\"].apply(crossref_search))\n",
    ")\n",
    "\n",
    "df[[\"doi\", \"crossref\"]].to_csv(\"library.csv\")\n",
    "\n",
    "(\n",
    "    df\n",
    "    .dropna()\n",
    "    .assign(title = lambda df: df[\"crossref\"].apply(get_title))\n",
    "    .assign(authors = lambda df: df[\"crossref\"].apply(get_authors))\n",
    "    .assign(filename = lambda df: df[\"doi\"].str.replace('/', '_'))\n",
    "    .dropna()\n",
    ")[[\"filename\", \"title\", \"authors\"]].to_markdown(root/'index.md', index=False, tablefmt = \"github\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(crossref_doi: dict) -> Optional[str]:\n",
    "    try:\n",
    "        return crossref_doi[\"title\"][0]\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "def get_authors(crossref_doi: dict) -> str:\n",
    "    try:\n",
    "        first_author = list()\n",
    "        authors = list()\n",
    "        for author in crossref_doi[\"author\"]:\n",
    "            name = f\"{author[\"given\"]} {author[\"family\"]}\"\n",
    "            if author[\"sequence\"] == \"first\":\n",
    "                first_author.append(name)\n",
    "            else:\n",
    "                authors.append(name)\n",
    "        return ', '.join(first_author + authors)\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "(\n",
    "    df\n",
    "    .dropna()\n",
    "    .assign(title = lambda df: df[\"crossref\"].apply(get_title))\n",
    "    .assign(authors = lambda df: df[\"crossref\"].apply(get_authors))\n",
    "    .assign(filename = lambda df: df[\"doi\"].str.replace('/', '_'))\n",
    "    .dropna()\n",
    ")[[\"filename\", \"title\", \"authors\"]].to_markdown(papers/'index.md', index=False, tablefmt = \"github\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_and_author(pdf: Path):\n",
    "    try:\n",
    "        metadata =  PdfReader(pdf).metadata\n",
    "        return metadata.title, metadata.author\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def request_isbn(title, author):\n",
    "    search_url = f\"https://www.googleapis.com/books/v1/volumes?q=intitle:{title}inauthor:{author}\"\n",
    "    search_ret = requests.get(search_url)\n",
    "    if search_ret.status_code != 200:\n",
    "        return None \n",
    "    try:\n",
    "        book_url = json.loads(search_ret.content)[\"items\"][0][\"selfLink\"]\n",
    "    except KeyError:\n",
    "        return None\n",
    "    book_ret = requests.get(book_url)\n",
    "    if book_ret.status_code != 200:\n",
    "        return None\n",
    "    book_data = json.loads(book_ret.content)\n",
    "    try:\n",
    "        return book_data[\"volumeInfo\"][\"industryIdentifiers\"][-1][\"identifier\"]\n",
    "    except KeyError:\n",
    "        return book_data[\"volumeInfo\"]\n",
    "\n",
    "df = (\n",
    "    pd.DataFrame({\"name\": books.rglob(\"*.pdf\")})\n",
    "    .assign(old_name = lambda df: df[\"name\"].apply(lambda x: x.name))\n",
    "    .assign(metadata = lambda df: df[\"name\"].apply(get_title_and_author))\n",
    "    .loc[lambda df: df[\"metadata\"].apply(lambda x: None not in x)]\n",
    "    .reset_index(drop = True)\n",
    "    .drop([9, 10, 14, 26, 35, 41, 44], axis = 0)\n",
    "    .reset_index(drop = True)\n",
    "    .assign(isbn = lambda df: df.apply(lambda x: request_isbn(x[\"metadata\"][0], x[\"metadata\"][1]), axis = 1))\n",
    ")\n",
    "df[[\"old_name\", \"isbn\"]].to_csv(\"library.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"The C Programming Language (Second Edition)\"\n",
    "author = \"Brian W. Kernighan\"\n",
    "search_url = f\"https://www.googleapis.com/books/v1/volumes?q=intitle:{title}inauthor:{author}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"library.csv\", index_col = 0)\n",
    "for _, row in df.iterrows():\n",
    "    shutil.move(books / row[\"old_name\"], books / f\"{row[\"isbn\"]}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    text = PdfReader(row[\"name\"]).pages[2].extract_text()\n",
    "    loc = text.find(\"Digital Object Identifier\")\n",
    "    shutil.move(row[\"name\"], papers / f\"{text.split('\\n')[1][26:].replace(' ', '')[:25].lower().replace('/', '_')}.pdf\")\n",
    "    #print(row[\"old_name\"], doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject(pdf: Path) -> str:\n",
    "    try:\n",
    "        subject_str = PdfReader(pdf).metadata.subject_raw\n",
    "        return subject_str if subject_str != '' else np.nan\n",
    "    except Exception:\n",
    "        return np.nan \n",
    "    \n",
    "def get_metadata(pdf: Path):\n",
    "    try:\n",
    "        return PdfReader(pdf).metadata\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def get_doi(subject: str) -> str:\n",
    "    idx = subject.find(\"doi.org/\")\n",
    "    if idx != -1:\n",
    "        return subject[idx+8:] \n",
    "\n",
    "    idx = subject.find(\"doi:\")\n",
    "    if idx != -1:\n",
    "        return subject[idx+4:] \n",
    "\n",
    "    doi = subject.split(';')[-1]\n",
    "    if doi is not None:\n",
    "        try:\n",
    "            if doi[2] == '.' and doi[7] == '/':\n",
    "                return doi\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "def get_crossref_metadata(meta):\n",
    "    try:\n",
    "        return next(iter(works.query(f\"{meta.replace(\"_\", \" \")}\")))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "works = Works()\n",
    "\n",
    "papers_df = (\n",
    "    pd.DataFrame({\"path\": papers.rglob(\"*.pdf\")})\n",
    "    .assign(old_name = lambda df: df[\"path\"].apply(lambda x: x.name))\n",
    "    .loc[lambda df: df[\"old_name\"].apply(lambda x: not x.startswith(\"10\"))]\n",
    "    .assign(metadata = lambda df: df[\"path\"].apply(get_metadata))\n",
    "    #.dropna()\n",
    "    .assign(crossref = lambda df: df[\"old_name\"].apply(get_crossref_metadata))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "#papers_df[[\"old_name\", \"subject\", \"doi\"]].to_csv(\"papers.csv\")\n",
    "display(papers_df)\n",
    "papers_df.to_csv(\"papers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"b\": 100, \"c\": 10, \"a\": 55}\n",
    "{k: d[k] for k in sorted(d) if k != \"b\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "(   \n",
    "    papers_df\n",
    "    .dropna()\n",
    "    .assign(crossref = lambda df: df[\"crossref\"].apply(lambda x: {k: x[k] for k in sorted(x) if k != \"reference\"}))\n",
    "    .assign(doi = lambda df: df[\"crossref\"].apply(lambda x:  x[\"DOI\"]))\n",
    "    .assign(url = lambda df: df[\"crossref\"].apply(lambda x:  x[\"URL\"]))\n",
    "    .sort_values(\"old_name\")\n",
    "    .reset_index(drop = True)\n",
    ")[[\"old_name\", \"doi\", \"url\"]].to_csv(\"papers.csv\")\n",
    "#papers_df[\"crossref\"].apply(lambda x: x[\"DOI\"].replace('/', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_arxiv(name: str) -> bool:\n",
    "    first = name.split('.')[0]\n",
    "    try:\n",
    "        return True if len(first) == 4 and first.isdigit() else False\n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "\n",
    "papers_df = (\n",
    "    pd.DataFrame({\"path\": papers.rglob(\"*.pdf\")})\n",
    "    .assign(old_name = lambda df: df[\"path\"].apply(lambda x: x.name))\n",
    "    .loc[lambda df: df[\"path\"].apply(lambda x: is_arxiv(x.name))]\n",
    "    .reset_index(drop = True)\n",
    ")\n",
    "papers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in papers_df.iterrows():\n",
    "    shutil.move(row[\"path\"], row[\"path\"].parent / f\"10.48550_{row[\"path\"].name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metacognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
