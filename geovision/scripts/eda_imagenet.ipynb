{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "log"
    }
   },
   "outputs": [],
   "source": [
    "torchvision resnet50 v2 on imagenet\n",
    "Acc@1 80.858 Acc@5 95.434\n",
    "\n",
    "torchrun --nproc_per_node=8 train.py --model resnet50 --batch-size 128 --lr 0.5 \\\n",
    "--lr-scheduler cosineannealinglr --lr-warmup-epochs 5 --lr-warmup-method linear \\\n",
    "--auto-augment ta_wide --epochs 600 --random-erase 0.1 --weight-decay 0.00002 \\\n",
    "--norm-weight-decay 0.0 --label-smoothing 0.1 --mixup-alpha 0.2 --cutmix-alpha 1.0 \\\n",
    "--train-crop-size 176 --model-ema --val-resize-size 232 \\\n",
    "--ra-sampler --ra-reps=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _list_corrupt_images(df: pd.DataFrame, archive_path: Path):\n",
    "    corrupted = list()\n",
    "    with zipfile.ZipFile(archive_path) as zf:\n",
    "        for idx, row in tqdm(df.iterrows(), total = len(df)):\n",
    "            try:\n",
    "                iio.imread(zf.read(row[\"image_path\"]), extension='.jpeg')\n",
    "            except Warning as w:\n",
    "                corrupted.append(idx)\n",
    "                print(f\"warning on idx = {idx}, [{w}]\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                corrupted.append(idx)\n",
    "                print(f\"exception on idx = {idx}, [{e}]\")\n",
    "                continue\n",
    "    return corrupted\n",
    "    \n",
    "def get_corrupt_images_df() -> pd.DataFrame:\n",
    "    archive_path = cls.local / \"staging\" / \"imagenet-object-localization-challenge.zip\"\n",
    "    df = cls.load(table = 'index', src = 'archive', subset = 'imagenet_1k')\n",
    "\n",
    "    # TODO: setup logging and write warnings/errors to a file instead of stdout and memory\n",
    "    warnings.filterwarnings('error')\n",
    "    with Pool(cpu_count()-1) as pool:\n",
    "        sus_idxs = pool.starmap(cls._list_corrupt_images, [(df.loc[idxs], archive_path) for idxs in np.array_split(df.index, cpu_count()-1)])\n",
    "    warnings.resetwarnings()\n",
    "\n",
    "    idxs = list() \n",
    "    for subarray in sus_idxs:\n",
    "        for idx in subarray:\n",
    "            idxs.append(idx)\n",
    "    df = df.loc[idxs]\n",
    "    df.to_hdf(archive_path.parent / \"metadata.h5\", key = \"corrupted\", mode = \"a\")\n",
    "    return df\n",
    "\n",
    "def filter_corrupt_images(cls, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.drop(index=cls.load(table = 'corrupt', src = 'archive', subset = 'imagenet_1k').index)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
