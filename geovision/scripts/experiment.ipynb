{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext memory_profiler \n",
    "%load_ext dotenv\n",
    "%autoreload 2\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Trainer\n",
    "from torchvision.transforms import v2 as T # type: ignore\n",
    "from geovision.logging import get_logger\n",
    "from geovision.config.basemodels import ExperimentConfig # noqa\n",
    "from geovision.data.module import ImageDatasetDataModule\n",
    "from geovision.io.local import get_ckpt_path, get_experiments_dir\n",
    "from geovision.training.module import ClassificationModule\n",
    "from geovision.training.loggers import (\n",
    "    get_csv_logger, \n",
    "    # get_wandb_logger,\n",
    "    get_ckpt_logger,\n",
    "    # get_lr_logger,\n",
    "    get_classification_logger\n",
    ")\n",
    "from geovision.analysis.plot_experiment import plot_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "from lightning import LightningModule\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "\n",
    "class TrainStepPrinter(Callback):\n",
    "    def __init__(self, config: ExperimentConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def on_load_checkpoint(self, trainer: Trainer, pl_module: LightningModule, checkpoint: Dict[str, Any]) -> None:\n",
    "        print(\"Callback: on_load_ckpt\")\n",
    "    \n",
    "    def on_train_batch_end(self, trainer: Trainer, pl_module: LightningModule, outputs: Dict[str, Any], batch: Any, batch_idx: int) -> None:\n",
    "        print(\"Callback: on_train_batch_end, trainer.global_step =\", trainer.global_step)\n",
    "    \n",
    "    def on_validation_batch_end(self, trainer: Trainer, pl_module: LightningModule, outputs: Dict[str, Any], batch: Any, batch_idx: int, dataloader_idx: int = 0) -> None:\n",
    "        print(\"Callback: on_val_batch_end, trainer.global_step =\", trainer.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import float32\n",
    "from geovision.data.imagenette import Imagenette\n",
    "\n",
    "logger = get_logger(\"experiment_logger\")\n",
    "transforms: dict[str, T.Transform | None] = {\n",
    "    \"image_transform\": T.Compose([\n",
    "        T.ToImage(), \n",
    "        T.Resize((224, 224), antialias=True), \n",
    "        T.ToDtype(float32, scale = True),\n",
    "        T.Normalize(Imagenette.means, Imagenette.std_devs),\n",
    "    ]),\n",
    "    \"target_transform\": None,\n",
    "    #\"common_transform\": None,\n",
    "    \"common_transform\": T.RandomChoice([\n",
    "        T.RandomHorizontalFlip(0.5),\n",
    "        T.RandomVerticalFlip(0.5),\n",
    "        T.RandomInvert(0.5),\n",
    "        T.RandomAutocontrast(0.5)\n",
    "    ]),\n",
    "}\n",
    "config = ExperimentConfig.from_yaml(\"config.yaml\", transforms)\n",
    "experiments_dir = get_experiments_dir(config)\n",
    "datamodule = ImageDatasetDataModule(config)\n",
    "\n",
    "loggers: list = list()\n",
    "loggers.append(csv_logger := get_csv_logger(config))\n",
    "# loggers.append(wandb_logger := get_wandb_logger(config))\n",
    "\n",
    "callbacks: list = list()\n",
    "#callbacks.append(TrainStepPrinter(config))\n",
    "#callbacks.append(ckpt_logger := get_ckpt_logger(config))\n",
    "callbacks.append(metrics_logger := get_classification_logger(config, log_every_n_steps=5))\n",
    "# callbacks.append(lr_logger := get_lr_logger(config))\n",
    "# callbacks.append(LearningRateFinder(num_training_steps=147, early_stop_threshold=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ckpt found in experiments, returning None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b8eb7bc7404b71866956fcccdff275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/step: 0, train/loss_step: 2.65226411819458\n",
      "log/step: 0, train/metric_step: 0.07187499850988388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aa29f3143046048d71108dbeccfa73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/epoch: 1, train/loss_epoch: 0.039523523300886154\n",
      "log/epoch: 1, train/metric_epoch: -0.04884595051407814\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs = 2,\n",
    "    check_val_every_n_epoch = 10,\n",
    "    num_sanity_val_steps = 0,\n",
    "    log_every_n_steps = 1,\n",
    "    limit_train_batches = 20,\n",
    "    limit_val_batches = 20,\n",
    "\n",
    "    logger = loggers,\n",
    "    callbacks = callbacks,\n",
    "    enable_checkpointing = False,\n",
    "    enable_model_summary = False\n",
    ")\n",
    "\n",
    "litmodule = ClassificationModule(ExperimentConfig.from_yaml(\"config.yaml\", transforms))\n",
    "trainer.fit(\n",
    "    model = litmodule,\n",
    "    datamodule = datamodule,\n",
    "    ckpt_path = get_ckpt_path(config, epoch = 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from geovision.analysis.viz import plot_confusion_matrix, plot_metrics_table\n",
    "%matplotlib tk\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (5, 5), layout = \"constrained\")\n",
    "plot_confusion_matrix(ax, np.random.randint(0, 10, (5, 5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
