{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext memory_profiler \n",
    "%load_ext dotenv\n",
    "%autoreload 2\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from lightning import Trainer\n",
    "from geovision.experiment.config import ExperimentConfig\n",
    "from geovision.data.interfaces import ImageDatasetDataModule\n",
    "from geovision.models.module import ClassificationModule\n",
    "\n",
    "from geovision.io.local import FileSystemIO as fs\n",
    "from geovision.experiment.loggers import (\n",
    "    get_csv_logger, \n",
    "    get_ckpt_logger,\n",
    "    get_classification_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExperimentConfig.from_yaml(\"config.yaml\")\n",
    "datamodule = ImageDatasetDataModule(config.dataset_constructor, config.dataset_config, config.dataloader_config)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    filename = f\"{fs.get_new_dir(\"logs\")/config.project_name}.log\",\n",
    "    filemode = \"a\",\n",
    "    format = \"%(asctime)s : %(name)s : %(levelname)s : %(message)s\",\n",
    "    level = logging.INFO\n",
    ")\n",
    "\n",
    "loggers: list = list()\n",
    "loggers.append(csv_logger := get_csv_logger(config))\n",
    "\n",
    "callbacks: list = list()\n",
    "callbacks.append(ckpt_logger := get_ckpt_logger(config))\n",
    "callbacks.append(metrics_logger := get_classification_logger(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"found ckpts: ['epoch=2_step=771.ckpt', 'epoch=5_step=1542.ckpt', 'epoch=8_step=2313.ckpt', 'epoch=9_step=2571.ckpt', 'epoch=11_step=3084.ckpt', 'epoch=11_step=3085.ckpt', 'epoch=13_step=3599.ckpt', 'epoch=14_step=3855.ckpt', 'epoch=15_step=4113.ckpt', 'epoch=17_step=4627.ckpt', '*epoch=19_step=5141.ckpt']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sambhav/miniconda3/envs/dev/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/sambhav/experiments/imagenette/logging_test/ckpts exists and is not empty.\n",
      "Restoring states from the checkpoint path at /home/sambhav/experiments/imagenette/logging_test/ckpts/epoch=19_step=5141.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | ResNet           | 11.2 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.716    Total estimated model params size (MB)\n",
      "87        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Restored all states from the checkpoint at /home/sambhav/experiments/imagenette/logging_test/ckpts/epoch=19_step=5141.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d000acbaf3e64083b90e609bfaaefb2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sambhav/miniconda3/envs/dev/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:161: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ac3f58f2854896b3e142f43683db52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd36f2ee13a45e084b4caf9f4d45343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=22` reached.\n"
     ]
    }
   ],
   "source": [
    "config = ExperimentConfig.from_yaml(\"config.yaml\")\n",
    "trainer = Trainer(logger = loggers, callbacks = callbacks, **config.trainer_params)\n",
    "trainer.fit(\n",
    "    model = ClassificationModule(config), \n",
    "    datamodule = datamodule, \n",
    "    ckpt_path = config.last_ckpt_path \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
